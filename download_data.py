import baostock as bs
import pandas as pd
import argparse
import os
from datetime import datetime
from loguru import logger
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum


class DataFrequency(Enum):
    """æ•°æ®é¢‘ç‡æšä¸¾"""
    DAILY = "d"      # æ—¥çº¿
    WEEKLY = "w"     # å‘¨çº¿
    MONTHLY = "m"    # æœˆçº¿
    MIN_5 = "5"      # 5åˆ†é’Ÿçº¿
    MIN_15 = "15"    # 15åˆ†é’Ÿçº¿
    MIN_30 = "30"    # 30åˆ†é’Ÿçº¿
    MIN_60 = "60"    # 60åˆ†é’Ÿçº¿


class AdjustFlag(Enum):
    """å¤æƒç±»å‹æšä¸¾"""
    POST_ADJUST = "1"   # åå¤æƒ
    PRE_ADJUST = "2"    # å‰å¤æƒ
    NO_ADJUST = "3"     # ä¸å¤æƒ


@dataclass
class DailyWeeklyMonthlyData:
    """æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿æ•°æ®ç»“æ„ï¼ˆåŒ…å«åœç‰Œè¯åˆ¸ï¼‰"""
    date: str           # äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD
    code: str           # è¯åˆ¸ä»£ç ï¼Œæ ¼å¼sh.XXXXXXæˆ–sz.XXXXXX
    open: float         # å¼€ç›˜ä»·
    high: float         # æœ€é«˜ä»·
    low: float          # æœ€ä½ä»·
    close: float        # æ”¶ç›˜ä»·
    preclose: float     # å‰æ”¶ç›˜ä»·
    volume: int         # æˆäº¤é‡ï¼ˆè‚¡ï¼‰
    amount: float       # æˆäº¤é¢ï¼ˆå…ƒï¼‰
    adjustflag: str     # å¤æƒçŠ¶æ€ï¼Œ1-åå¤æƒï¼Œ2-å‰å¤æƒï¼Œ3-ä¸å¤æƒ
    turn: Optional[float]  # æ¢æ‰‹ç‡ï¼Œåœç‰Œæ—¶ä¸ºç©º
    tradestatus: str    # äº¤æ˜“çŠ¶æ€ï¼Œ1-æ­£å¸¸äº¤æ˜“ï¼Œ0-åœç‰Œ
    pctChg: float       # æ¶¨è·Œå¹…ï¼ˆ%ï¼‰
    isST: str           # æ˜¯å¦STè‚¡ç¥¨ï¼Œ1-æ˜¯ï¼Œ0-å¦


@dataclass
class MinuteData:
    """åˆ†é’Ÿçº¿æ•°æ®ç»“æ„ï¼ˆ5ã€15ã€30ã€60åˆ†é’Ÿï¼Œä¸åŒ…å«æŒ‡æ•°ï¼‰"""
    date: str           # äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD
    time: str           # äº¤æ˜“æ—¶é—´ï¼Œæ ¼å¼HH:MM:SS
    code: str           # è¯åˆ¸ä»£ç ï¼Œæ ¼å¼sh.XXXXXXæˆ–sz.XXXXXX
    open: float         # å¼€ç›˜ä»·
    high: float         # æœ€é«˜ä»·
    low: float          # æœ€ä½ä»·
    close: float        # æ”¶ç›˜ä»·
    volume: int         # æˆäº¤é‡ï¼ˆè‚¡ï¼‰
    amount: float       # æˆäº¤é¢ï¼ˆå…ƒï¼‰
    adjustflag: str     # å¤æƒçŠ¶æ€ï¼Œ1-åå¤æƒï¼Œ2-å‰å¤æƒï¼Œ3-ä¸å¤æƒ


class DataFieldsConfig:
    """æ•°æ®å­—æ®µé…ç½®ç±»"""
    
    # æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿å­—æ®µï¼ˆåŒ…å«åœç‰Œè¯åˆ¸ï¼‰
    DAILY_WEEKLY_MONTHLY_FIELDS = [
        "date",         # äº¤æ˜“æ—¥æœŸ
        "code",         # è¯åˆ¸ä»£ç 
        "open",         # å¼€ç›˜ä»·
        "high",         # æœ€é«˜ä»·
        "low",          # æœ€ä½ä»·
        "close",        # æ”¶ç›˜ä»·
        "preclose",     # å‰æ”¶ç›˜ä»·
        "volume",       # æˆäº¤é‡
        "amount",       # æˆäº¤é¢
        "adjustflag",   # å¤æƒçŠ¶æ€
        "turn",         # æ¢æ‰‹ç‡
        "tradestatus",  # äº¤æ˜“çŠ¶æ€
        "pctChg",       # æ¶¨è·Œå¹…
        "isST"          # æ˜¯å¦STè‚¡ç¥¨
    ]
    
    # åˆ†é’Ÿçº¿å­—æ®µï¼ˆ5ã€15ã€30ã€60åˆ†é’Ÿï¼Œä¸åŒ…å«æŒ‡æ•°ï¼‰
    MINUTE_FIELDS = [
        "date",         # äº¤æ˜“æ—¥æœŸ
        "time",         # äº¤æ˜“æ—¶é—´
        "code",         # è¯åˆ¸ä»£ç 
        "open",         # å¼€ç›˜ä»·
        "high",         # æœ€é«˜ä»·
        "low",          # æœ€ä½ä»·
        "close",        # æ”¶ç›˜ä»·
        "volume",       # æˆäº¤é‡
        "amount",       # æˆäº¤é¢
        "adjustflag"    # å¤æƒçŠ¶æ€
    ]
    
    @classmethod
    def get_fields_by_frequency(cls, frequency: str) -> List[str]:
        """æ ¹æ®é¢‘ç‡è·å–å¯¹åº”çš„å­—æ®µåˆ—è¡¨"""
        if frequency in ["5", "15", "30", "60"]:
            return cls.MINUTE_FIELDS
        else:
            return cls.DAILY_WEEKLY_MONTHLY_FIELDS
    
    @classmethod
    def get_fields_string(cls, frequency: str) -> str:
        """è·å–å­—æ®µå­—ç¬¦ä¸²ï¼Œç”¨äºAPIè°ƒç”¨"""
        fields = cls.get_fields_by_frequency(frequency)
        return ",".join(fields)


def setup_logging(log_dir='log'):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # æ—¥å¿—åº“é»˜è®¤è¾“å‡ºåˆ°ç»ˆç«¯ï¼Œç§»é™¤ç»ˆç«¯çš„æ—¥å¿—ï¼Œç›®å‰ä¿ç•™ç»ˆç«¯çš„æ—¥å¿—
    # logger.remove()
    
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    log_file = os.path.join(log_dir, 'download_data_{time:YYYY-MM-DD}.log')
    
    # æ·»åŠ æ—¥å¿—è®°å½•å™¨ï¼ŒæŒ‰å¤©æ»šåŠ¨ï¼Œå¹¶ä¿ç•™30å¤©çš„æ—¥å¿—
    log_format = "{time:YYYY-MM-DD HH:mm:ss} - {level} - {name}:{function}:{line} - {message}"
    logger.add(log_file, rotation="00:00", retention="30 days", level="DEBUG", format=log_format)


def download_stock_data(stock_code: str, start_date: str, end_date: str, 
                       frequency: str = "d", adjustflag: str = "2") -> Optional[pd.DataFrame]:
    """ä¸‹è½½è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼å¦‚ sh.600000 æˆ– sz.000001
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD
        frequency: æ•°æ®é¢‘ç‡ï¼Œæ”¯æŒ d/w/m/5/15/30/60
        adjustflag: å¤æƒç±»å‹ï¼Œ1-åå¤æƒï¼Œ2-å‰å¤æƒï¼Œ3-ä¸å¤æƒ
    
    Returns:
        pandas.DataFrame: è‚¡ç¥¨æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    logger.info(f"å¼€å§‹ä¸‹è½½è‚¡ç¥¨æ•°æ®: {stock_code}, æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}, é¢‘ç‡: {frequency}")
    
    # éªŒè¯é¢‘ç‡å‚æ•°
    valid_frequencies = [freq.value for freq in DataFrequency]
    if frequency not in valid_frequencies:
        logger.error(f"æ— æ•ˆçš„é¢‘ç‡å‚æ•°: {frequency}, æ”¯æŒçš„é¢‘ç‡: {valid_frequencies}")
        return None
    
    # éªŒè¯å¤æƒå‚æ•°
    valid_adjustflags = [flag.value for flag in AdjustFlag]
    if adjustflag not in valid_adjustflags:
        logger.error(f"æ— æ•ˆçš„å¤æƒå‚æ•°: {adjustflag}, æ”¯æŒçš„å¤æƒç±»å‹: {valid_adjustflags}")
        return None
    
    #### ç™»é™†ç³»ç»Ÿ ####
    lg = bs.login()
    logger.info(f'ç™»å½•å“åº” error_code: {lg.error_code}')
    logger.info(f'ç™»å½•å“åº” error_msg: {lg.error_msg}')
    
    if lg.error_code != '0':
        logger.error(f"ç™»å½•å¤±è´¥: {lg.error_msg}")
        return None
    
    try:
        #### è·å–æ²ªæ·±Aè‚¡å†å²Kçº¿æ•°æ® ####
        # æ ¹æ®é¢‘ç‡è·å–å¯¹åº”çš„å­—æ®µé…ç½®
        fields = DataFieldsConfig.get_fields_string(frequency)
        logger.info(f"ä½¿ç”¨å­—æ®µé…ç½®: {fields}")
        
        # åˆ†é’Ÿçº¿æ•°æ®ä¸åŒ…å«æŒ‡æ•°ï¼Œéœ€è¦éªŒè¯è‚¡ç¥¨ä»£ç 
        if frequency in ["5", "15", "30", "60"]:
            if not (stock_code.startswith('sh.') or stock_code.startswith('sz.')):
                logger.error(f"åˆ†é’Ÿçº¿æ•°æ®ä¸æ”¯æŒæŒ‡æ•°ä»£ç : {stock_code}")
                return None
        
        rs = bs.query_history_k_data_plus(stock_code, fields,
                                         start_date=start_date, end_date=end_date,
                                         frequency=frequency, adjustflag=adjustflag)
        
        logger.info(f'æŸ¥è¯¢å“åº” error_code: {rs.error_code}')
        logger.info(f'æŸ¥è¯¢å“åº” error_msg: {rs.error_msg}')
        
        if rs.error_code != '0':
            logger.error(f"æŸ¥è¯¢æ•°æ®å¤±è´¥: {rs.error_msg}")
            return None
        
        #### æ‰“å°ç»“æœé›† ####
        data_list = []
        while (rs.error_code == '0') & rs.next():
            # è·å–ä¸€æ¡è®°å½•ï¼Œå°†è®°å½•åˆå¹¶åœ¨ä¸€èµ·
            data_list.append(rs.get_row_data())
        
        result = pd.DataFrame(data_list, columns=rs.fields)
        logger.info(f"æˆåŠŸè·å– {len(result)} æ¡æ•°æ®")
        
        # æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯
        if not result.empty:
            result = validate_and_convert_data(result, frequency)
        
        return result
        
    except Exception as e:
        logger.error(f"ä¸‹è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None
    finally:
        #### ç™»å‡ºç³»ç»Ÿ ####
        bs.logout()
        logger.info("å·²ç™»å‡ºç³»ç»Ÿ")


def validate_and_convert_data(df: pd.DataFrame, frequency: str) -> pd.DataFrame:
    """éªŒè¯å’Œè½¬æ¢æ•°æ®ç±»å‹
    
    Args:
        df: åŸå§‹æ•°æ®DataFrame
        frequency: æ•°æ®é¢‘ç‡
    
    Returns:
        è½¬æ¢åçš„DataFrame
    """
    try:
        # æ ¹æ®é¢‘ç‡ç¡®å®šæ•°æ®ç±»å‹
        if frequency in ["5", "15", "30", "60"]:
            # åˆ†é’Ÿçº¿æ•°æ®è½¬æ¢
            numeric_cols = ["open", "high", "low", "close", "volume", "amount"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        else:
            # æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿æ•°æ®è½¬æ¢
            numeric_cols = ["open", "high", "low", "close", "preclose", "volume", "amount", "pctChg"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # ç‰¹æ®Šå¤„ç†æ¢æ‰‹ç‡ï¼Œå¯èƒ½ä¸ºç©ºå­—ç¬¦ä¸²
            if "turn" in df.columns:
                df["turn"] = df["turn"].apply(lambda x: float(x) if x else None)
        
        logger.info("æ•°æ®ç±»å‹è½¬æ¢æˆåŠŸ")
        return df
    
    except Exception as e:
        logger.warning(f"æ•°æ®ç±»å‹è½¬æ¢è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {str(e)}")
        return df


def generate_filename(stock_code: str, start_date: str, end_date: str, frequency: str) -> str:
    """ç”Ÿæˆæ–‡ä»¶å
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        frequency: æ•°æ®é¢‘ç‡
    
    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶å
    """
    # æ¸…ç†è‚¡ç¥¨ä»£ç ï¼Œç§»é™¤å‰ç¼€
    clean_code = stock_code.replace('sh.', '').replace('sz.', '')
    
    # é¢‘ç‡æ˜ å°„
    freq_map = {
        DataFrequency.DAILY.value: 'daily',
        DataFrequency.WEEKLY.value: 'weekly', 
        DataFrequency.MONTHLY.value: 'monthly',
        DataFrequency.MIN_5.value: '5min',
        DataFrequency.MIN_15.value: '15min',
        DataFrequency.MIN_30.value: '30min',
        DataFrequency.MIN_60.value: '60min'
    }
    
    freq_str = freq_map.get(frequency, frequency)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    filename = f"{clean_code}_{freq_str}_{start_date}_{end_date}_{timestamp}.csv"
    return filename


def get_data_info(frequency: str) -> str:
    """è·å–æ•°æ®ç±»å‹ä¿¡æ¯
    
    Args:
        frequency: æ•°æ®é¢‘ç‡
    
    Returns:
        æ•°æ®ç±»å‹æè¿°ä¿¡æ¯
    """
    if frequency in ["5", "15", "30", "60"]:
        return f"{frequency}åˆ†é’Ÿçº¿æ•°æ®ï¼ˆä¸åŒ…å«æŒ‡æ•°ï¼‰"
    elif frequency == "d":
        return "æ—¥çº¿æ•°æ®ï¼ˆåŒ…å«åœç‰Œè¯åˆ¸ï¼‰"
    elif frequency == "w":
        return "å‘¨çº¿æ•°æ®ï¼ˆåŒ…å«åœç‰Œè¯åˆ¸ï¼‰"
    elif frequency == "m":
        return "æœˆçº¿æ•°æ®ï¼ˆåŒ…å«åœç‰Œè¯åˆ¸ï¼‰"
    else:
        return "æœªçŸ¥æ•°æ®ç±»å‹"


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä¸‹è½½è‚¡ç¥¨å†å²æ•°æ® - æ”¯æŒæ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿ã€åˆ†é’Ÿçº¿æ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ•°æ®ç±»å‹è¯´æ˜:
  æ—¥çº¿/å‘¨çº¿/æœˆçº¿: åŒ…å«åœç‰Œè¯åˆ¸ï¼Œå­—æ®µåŒ…æ‹¬å¼€é«˜ä½æ”¶ã€å‰æ”¶ç›˜ä»·ã€æˆäº¤é‡é¢ã€æ¢æ‰‹ç‡ã€äº¤æ˜“çŠ¶æ€ã€æ¶¨è·Œå¹…ã€STæ ‡è¯†
  åˆ†é’Ÿçº¿æ•°æ®: ä¸åŒ…å«æŒ‡æ•°ï¼Œå­—æ®µåŒ…æ‹¬å¼€é«˜ä½æ”¶ã€æˆäº¤é‡é¢ã€æ—¶é—´ä¿¡æ¯

ç¤ºä¾‹:
  python download_data.py -c sh.600000 -s 2024-01-01 -e 2024-12-31
  python download_data.py -c sz.000001 -s 2024-01-01 -e 2024-12-31 -f 5 -a 1
        """
    )
    
    parser.add_argument('--code', '-c', required=True, 
                       help='è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼: sh.XXXXXXæˆ–sz.XXXXXXï¼ˆåˆ†é’Ÿçº¿ä¸æ”¯æŒæŒ‡æ•°ï¼‰')
    parser.add_argument('--start', '-s', required=True, 
                       help='å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD')
    parser.add_argument('--end', '-e', required=True, 
                       help='ç»“æŸæ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD')
    parser.add_argument('--frequency', '-f', default=DataFrequency.DAILY.value, 
                       choices=[freq.value for freq in DataFrequency],
                       help='æ•°æ®é¢‘ç‡: d=æ—¥çº¿, w=å‘¨çº¿, m=æœˆçº¿, 5/15/30/60=åˆ†é’Ÿçº¿')
    parser.add_argument('--adjustflag', '-a', default=AdjustFlag.PRE_ADJUST.value, 
                       choices=[flag.value for flag in AdjustFlag],
                       help='å¤æƒç±»å‹: 1=åå¤æƒ, 2=å‰å¤æƒ, 3=ä¸å¤æƒ')
    parser.add_argument('--output-dir', '-o', default='data', 
                       help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºdata')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # æ˜¾ç¤ºä¸‹è½½ä¿¡æ¯
    data_type_info = get_data_info(args.frequency)
    print(f"\n=== è‚¡ç¥¨æ•°æ®ä¸‹è½½å·¥å…· ===")
    print(f"è‚¡ç¥¨ä»£ç : {args.code}")
    print(f"æ—¶é—´èŒƒå›´: {args.start} è‡³ {args.end}")
    print(f"æ•°æ®ç±»å‹: {data_type_info}")
    print(f"å¤æƒæ–¹å¼: {AdjustFlag(args.adjustflag).name}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print("=" * 30)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)
        logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {args.output_dir}")
    
    # ä¸‹è½½æ•°æ®
    result = download_stock_data(args.code, args.start, args.end, args.frequency, args.adjustflag)
    
    if result is not None and not result.empty:
        # ç”Ÿæˆæ–‡ä»¶å
        filename = generate_filename(args.code, args.start, args.end, args.frequency)
        filepath = os.path.join(args.output_dir, filename)
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        result.to_csv(filepath, index=False, encoding='utf-8-sig')
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        
        # æ˜¾ç¤ºç»“æœä¿¡æ¯
        print(f"\nâœ… æ•°æ®ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“Š æ•°æ®è®°å½•æ•°: {len(result)} æ¡")
        print(f"ğŸ“ æ–‡ä»¶ä¿å­˜è·¯å¾„: {filepath}")
        print(f"ğŸ“‹ æ•°æ®å­—æ®µ: {', '.join(result.columns.tolist())}")
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        print(f"\nğŸ“ˆ æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰:")
        print(result.head().to_string(index=False))
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
        if 'close' in result.columns:
            print(f"\nğŸ“Š ä»·æ ¼ç»Ÿè®¡ä¿¡æ¯:")
            close_prices = pd.to_numeric(result['close'], errors='coerce')
            print(f"   æœ€é«˜ä»·: {close_prices.max():.2f}")
            print(f"   æœ€ä½ä»·: {close_prices.min():.2f}")
            print(f"   å¹³å‡ä»·: {close_prices.mean():.2f}")
            
    else:
        logger.error("æœªèƒ½è·å–åˆ°æœ‰æ•ˆæ•°æ®")
        print("\nâŒ æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹é¡¹ç›®:")
        print("   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   2. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("   3. æ—¥æœŸèŒƒå›´æ˜¯å¦åˆç†")
        print("   4. åˆ†é’Ÿçº¿æ•°æ®æ˜¯å¦ä½¿ç”¨äº†æŒ‡æ•°ä»£ç ")


if __name__ == "__main__":
    main()